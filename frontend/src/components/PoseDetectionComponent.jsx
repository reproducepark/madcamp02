// src/components/PoseDetectionComponent.jsx
import React, { useEffect, useRef, useState, useCallback } from "react";
import * as tf from "@tensorflow/tfjs";

// ëª¨ë¸ ê²½ë¡œë¥¼ ë™ì ìœ¼ë¡œ ì„¤ì •
const getModelUrl = () => {
  // ê°œë°œ í™˜ê²½ì—ì„œëŠ” ìƒëŒ€ ê²½ë¡œ ì‚¬ìš©
  if (import.meta.env.DEV) {
    return "/model/model.json";
  }
  
  // Electron í™˜ê²½ì—ì„œëŠ” file:// í”„ë¡œí† ì½œ ì‚¬ìš©
  if (window.electronAPI) {
    return "./model/model.json";
  }
  
  // ì›¹ í™˜ê²½ì—ì„œëŠ” ìƒëŒ€ ê²½ë¡œ ì‚¬ìš©
  return "./model/model.json";
};

const MODEL_URL = getModelUrl();

const KEYPOINT_NAMES = [
  "ì½”", "ì™¼ìª½ ëˆˆ", "ì˜¤ë¥¸ìª½ ëˆˆ", "ì™¼ìª½ ê·€", "ì˜¤ë¥¸ìª½ ê·€",
  "ì™¼ìª½ ì–´ê¹¨", "ì˜¤ë¥¸ìª½ ì–´ê¹¨", "ì™¼ìª½ íŒ”ê¿ˆì¹˜", "ì˜¤ë¥¸ìª½ íŒ”ê¿ˆì¹˜",
  "ì™¼ìª½ ì†ëª©", "ì˜¤ë¥¸ìª½ ì†ëª©", "ì™¼ìª½ ì—‰ë©ì´", "ì˜¤ë¥¸ìª½ ì—‰ë©ì´",
  "ì™¼ìª½ ë¬´ë¦", "ì˜¤ë¥¸ìª½ ë¬´ë¦", "ì™¼ìª½ ë°œëª©", "ì˜¤ë¥¸ìª½ ë°œëª©"
];

// í‚¤í¬ì¸íŠ¸ ì—°ê²°ì„  ì •ì˜ (ì˜ˆ: MoveNetì˜ ìŠ¤ì¼ˆë ˆí†¤ê³¼ ìœ ì‚¬í•˜ê²Œ)
// ì´ ì—°ê²°ì„ ì€ ë°”ìš´ë”© ë°•ìŠ¤ì™€ ë³„ê°œë¡œ ì‚¬ëŒì˜ ìì„¸ë¥¼ ë” ëª…í™•í•˜ê²Œ ë³´ì—¬ì¤ë‹ˆë‹¤.
const KEYPOINT_CONNECTIONS = [
    [0, 1], [0, 2], // ì½”-ëˆˆ
    [1, 3], [2, 4], // ëˆˆ-ê·€
    [5, 6],         // ì–´ê¹¨
    [5, 7], [7, 9], // ì™¼ìª½ íŒ”
    [6, 8], [8, 10], // ì˜¤ë¥¸ìª½ íŒ”
    [5, 11], [6, 12], // ì–´ê¹¨-ì—‰ë©ì´
    [11, 12],       // ì—‰ë©ì´
    [11, 13], [13, 15], // ì™¼ìª½ ë‹¤ë¦¬
    [12, 14], [14, 16]  // ì˜¤ë¥¸ìª½ ë‹¤ë¦¬
];

function PoseDetectionComponent({ videoRef, onRecognitionChange, onKeypointsChange }) {
  const canvasRef = useRef(null);
  const [model, setModel] = useState(null);
  const [loading, setLoading] = useState(true);
  const [errorMessage, setErrorMessage] = useState("");
  const intervalRef = useRef(null);

  // ëª¨ë¸ ë¡œë“œ
  useEffect(() => {
    async function loadModel() {
      console.log("=== ëª¨ë¸ ë¡œë“œ ì‹œì‘ ===");
      console.log("ì´ˆê¸° MODEL_URL:", MODEL_URL);
      console.log("í˜„ì¬ í™˜ê²½:", import.meta.env.DEV ? "ê°œë°œ" : "í”„ë¡œë•ì…˜");
      console.log("window.location.href:", window.location.href);
      console.log("window.location.pathname:", window.location.pathname);
      
      setLoading(true);
      setErrorMessage(""); // ì—ëŸ¬ ë©”ì‹œì§€ ì´ˆê¸°í™”
      
      // ì—¬ëŸ¬ ê²½ë¡œë¥¼ ì‹œë„
      const modelPaths = [
        MODEL_URL,
        "/model/model.json",
        "./model/model.json",
        "model/model.json"
      ];
      
      console.log("ì‹œë„í•  ëª¨ë¸ ê²½ë¡œë“¤:", modelPaths);
      
      for (let i = 0; i < modelPaths.length; i++) {
        const path = modelPaths[i];
        console.log(`\n--- ${i + 1}ë²ˆì§¸ ì‹œë„: ${path} ---`);
        
        try {
          console.log("TensorFlow.js ì´ˆê¸°í™” ì‹œì‘...");
          await tf.ready();
          console.log("TensorFlow.js ì´ˆê¸°í™” ì™„ë£Œ");
          
          console.log("ëª¨ë¸ ë¡œë“œ ì‹œì‘...");
          const loadedModel = await tf.loadGraphModel(path, {
            onProgress: (fraction) => {
              console.log(`ëª¨ë¸ ë¡œë“œ ì§„í–‰ë¥ : ${(fraction * 100).toFixed(1)}%`);
            }
          });
          
          console.log("ëª¨ë¸ ë¡œë“œ ì„±ê³µ!");
          console.log("ë¡œë“œëœ ëª¨ë¸ ì •ë³´:", {
            inputs: loadedModel.inputs,
            outputs: loadedModel.outputs,
            modelUrl: loadedModel.modelUrl
          });
          
          setModel(loadedModel);
          setLoading(false);
          console.log("=== ëª¨ë¸ ë¡œë“œ ì™„ë£Œ ===");
          return; // ì„±ê³µí•˜ë©´ í•¨ìˆ˜ ì¢…ë£Œ
          
        } catch (error) {
          console.error(`ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ (${path}):`, error);
          console.error("ì—ëŸ¬ ìƒì„¸ ì •ë³´:", {
            name: error.name,
            message: error.message,
            stack: error.stack
          });
          
          // ë„¤íŠ¸ì›Œí¬ ì—ëŸ¬ì¸ì§€ í™•ì¸
          if (error.message.includes("Failed to fetch")) {
            console.error("ë„¤íŠ¸ì›Œí¬ ì—ëŸ¬ - íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ");
          } else if (error.message.includes("JSON")) {
            console.error("JSON íŒŒì‹± ì—ëŸ¬ - íŒŒì¼ í˜•ì‹ ë¬¸ì œ");
          }
          
          continue; // ë‹¤ìŒ ê²½ë¡œ ì‹œë„
        }
      }
      
      // ëª¨ë“  ê²½ë¡œê°€ ì‹¤íŒ¨í•œ ê²½ìš°
      console.error("=== ëª¨ë“  ëª¨ë¸ ê²½ë¡œì—ì„œ ë¡œë“œ ì‹¤íŒ¨ ===");
      console.error("ì‹œë„í•œ ê²½ë¡œë“¤:", modelPaths);
      setErrorMessage("ëª¨ë¸ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ëª¨ë¸ íŒŒì¼ì´ ì˜¬ë°”ë¥¸ ìœ„ì¹˜ì— ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.");
      setLoading(false);
    }
    
    console.log("loadModel í•¨ìˆ˜ í˜¸ì¶œ");
    loadModel();
  }, []);

  // runPose í•¨ìˆ˜ë¥¼ useCallbackìœ¼ë¡œ ì •ì˜
  const runPose = useCallback(async () => {
    console.log("ğŸ”„ runPose í•¨ìˆ˜ ì‹¤í–‰ - ì‹œê°„:", new Date().toLocaleTimeString());
    
    if (!videoRef.current) {
      console.log("âŒ ë¹„ë””ì˜¤ ref ì—†ìŒ");
      return;
    }
    
    if (videoRef.current.readyState !== 4) {
      console.log("âŒ ë¹„ë””ì˜¤ ì¤€ë¹„ë˜ì§€ ì•ŠìŒ (readyState:", videoRef.current.readyState, ")");
      return;
    }

    const video = videoRef.current;
    const canvas = canvasRef.current;
    
    console.log("ë¹„ë””ì˜¤ í¬ê¸°:", video.videoWidth, "x", video.videoHeight);
    
    // Canvas ìš”ì†Œ ì¡´ì¬ ì—¬ë¶€ë¥¼ ë” ì•ˆì „í•˜ê²Œ í™•ì¸
    if (!canvas) {
      console.warn("âŒ Canvas element not found. Waiting for canvas to be ready...");
      return;
    }
    
    // Canvasê°€ DOMì— ì‹¤ì œë¡œ ì—°ê²°ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
    if (!document.contains(canvas)) {
      console.warn("âŒ Canvas element not in DOM. Waiting...");
      return;
    }
    
    console.log("âœ… Canvas ì¤€ë¹„ë¨, ì¶”ë¡  ì‹œì‘");

    const ctx = canvas.getContext("2d");
    const modelInputSize = 640; // ëª¨ë¸ ì…ë ¥ í¬ê¸°

    // 1. ìº”ë²„ìŠ¤ë¥¼ íˆ¬ëª…í•˜ê²Œ ì´ˆê¸°í™”
    ctx.clearRect(0, 0, modelInputSize, modelInputSize);

    // 2. ì¶”ë¡ ìš© ì„ì‹œ ìº”ë²„ìŠ¤ ìƒì„± (í™”ë©´ì— í‘œì‹œë˜ì§€ ì•ŠìŒ)
    const tempCanvas = document.createElement('canvas');
    tempCanvas.width = modelInputSize;
    tempCanvas.height = modelInputSize;
    const tempCtx = tempCanvas.getContext('2d');

    // 3. ë¹„ë””ì˜¤ í”„ë ˆì„ì„ ì„ì‹œ ìº”ë²„ìŠ¤ì— ê·¸ë¦¬ê¸°
    const videoWidth = video.videoWidth;
    const videoHeight = video.videoHeight;

    let scaledWidth, scaledHeight;
    const aspectRatio = videoWidth / videoHeight;

    if (aspectRatio > 1) { // ë¹„ë””ì˜¤ê°€ ê°€ë¡œë¡œ ë” ê¸¸ë©´, í­ì„ 640ìœ¼ë¡œ ë§ì¶”ê³  ë†’ì´ ì¡°ì •
      scaledWidth = modelInputSize;
      scaledHeight = modelInputSize / aspectRatio;
    } else { // ë¹„ë””ì˜¤ê°€ ì„¸ë¡œë¡œ ë” ê¸¸ê±°ë‚˜ ì •ì‚¬ê°í˜•ì´ë©´, ë†’ì´ë¥¼ 640ìœ¼ë¡œ ë§ì¶”ê³  í­ ì¡°ì •
      scaledHeight = modelInputSize;
      scaledWidth = modelInputSize * aspectRatio;
    }

    const offsetX = (modelInputSize - scaledWidth) / 2;
    const offsetY = (modelInputSize - scaledHeight) / 2;

    // ì„ì‹œ ìº”ë²„ìŠ¤ì— ë¹„ë””ì˜¤ í”„ë ˆì„ ê·¸ë¦¬ê¸°
    tempCtx.drawImage(video, offsetX, offsetY, scaledWidth, scaledHeight);

    // 4. ì„ì‹œ ìº”ë²„ìŠ¤ í”½ì…€ì„ í…ì„œë¡œ ë³€í™˜
    const input = tf.browser.fromPixels(tempCanvas)
      .toFloat()
      .div(tf.scalar(255))
      .expandDims(0);

    let output = null;
    let processedOutput = null;

    try {
      // 3. ì¶”ë¡ 
      output = model.predict(input);

      // YOLOv8/11 pose ëª¨ë¸ì˜ ì¶œë ¥ í˜•íƒœì— ë”°ë¼ ì „ì¹˜
      if (output.shape && output.shape.length === 3 && output.shape[1] === 56 && output.shape[2] === 8400) {
        processedOutput = output.transpose([0, 2, 1]); // [1, 8400, 56]
      } else {
        processedOutput = output;
      }

      const arr = await processedOutput.array();
      const detections = arr ? arr[0] : [];

      // 4. ê°€ì¥ ë†’ì€ ì‹ ë¢°ë„ë¥¼ ê°€ì§„ ê°ì§€ ê²°ê³¼ ì°¾ê¸°
      const BBOX_CONF_THRESHOLD = 0.25;
      const KEYPOINT_VIS_THRESHOLD = 0.3;

      let bestDetection = null;
      let highestConfidence = 0;

      // ê°€ì¥ ë†’ì€ ì‹ ë¢°ë„ë¥¼ ê°€ì§„ ê°ì§€ ê²°ê³¼ ì°¾ê¸°
      detections.forEach((det) => {
        const confidence = det && det.length > 4 ? det[4] : 0;
        if (confidence > BBOX_CONF_THRESHOLD && confidence > highestConfidence) {
          highestConfidence = confidence;
          bestDetection = det;
        }
      });

      // 5. ê°€ì¥ ë†’ì€ ì‹ ë¢°ë„ì˜ í‚¤í¬ì¸íŠ¸ë§Œ ì‹œê°í™”
      // ë¹„ë””ì˜¤ í¬ê¸°ì— ë§ê²Œ ìŠ¤ì¼€ì¼ë§ íŒ©í„° ê³„ì‚°
      const canvasWidth = canvas.width;
      const canvasHeight = canvas.height;
      const scaleX = canvasWidth / modelInputSize;
      const scaleY = canvasHeight / modelInputSize;
      
      ctx.lineWidth = 2;
      ctx.strokeStyle = 'rgba(0, 255, 0, 0)'; // íˆ¬ëª…í•œ ë¼ì„ìƒ‰
      ctx.fillStyle = 'rgba(255, 0, 0, 0)'; // íˆ¬ëª…í•œ ë¹¨ê°„ìƒ‰
      ctx.font = '12px Arial';

      let hasValidDetection = false;
      let faceDetected = false;
      let leftShoulderDetected = false;
      let rightShoulderDetected = false;

      if (bestDetection) {
        hasValidDetection = true;
        
        // ë°”ìš´ë”© ë°•ìŠ¤
        const x_center = bestDetection[0];
        const y_center = bestDetection[1];
        const width = bestDetection[2];
        const height = bestDetection[3];

        const x1 = x_center - width / 2;
        const y1 = y_center - height / 2;

        // ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸° (ìŠ¤ì¼€ì¼ë§ ì ìš©)
        ctx.beginPath();
        ctx.rect(x1 * scaleX, y1 * scaleY, width * scaleX, height * scaleY);
        ctx.stroke();

        // ì‹ ë¢°ë„ í…ìŠ¤íŠ¸ í‘œì‹œ (ìŠ¤ì¼€ì¼ë§ ì ìš©) - íˆ¬ëª…í•˜ê²Œ ì„¤ì •
        ctx.fillStyle = 'rgba(255, 255, 255, 0)'; // íˆ¬ëª…í•œ í°ìƒ‰
        ctx.fillText(`Confidence: ${highestConfidence.toFixed(2)}`, x1 * scaleX, y1 * scaleY > 10 ? y1 * scaleY - 5 : y1 * scaleY + 15);
        ctx.fillStyle = 'rgba(255, 0, 0, 0)'; // íˆ¬ëª…í•œ ë¹¨ê°„ìƒ‰

        const keypoints = [];
        // í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ ë° ê·¸ë¦¬ê¸°
        for (let i = 0; i < 17; i++) {
          const kx = bestDetection[5 + i * 3];
          const ky = bestDetection[5 + i * 3 + 1];
          const visibility = bestDetection[5 + i * 3 + 2];

          if (visibility > KEYPOINT_VIS_THRESHOLD) {
            ctx.beginPath();
            ctx.arc(kx * scaleX, ky * scaleY, 4, 0, 2 * Math.PI);
            ctx.fill();
            keypoints.push({ x: kx * scaleX, y: ky * scaleY, score: visibility, name: KEYPOINT_NAMES[i] });
            
            // ì–¼êµ´ í‚¤í¬ì¸íŠ¸ í™•ì¸ (ì½”, ì™¼ìª½ ëˆˆ, ì˜¤ë¥¸ìª½ ëˆˆ, ì™¼ìª½ ê·€, ì˜¤ë¥¸ìª½ ê·€)
            if (i >= 0 && i <= 4) {
              faceDetected = true;
            }
            // ì–´ê¹¨ í‚¤í¬ì¸íŠ¸ í™•ì¸ (ì™¼ìª½ ì–´ê¹¨, ì˜¤ë¥¸ìª½ ì–´ê¹¨)
            if (i === 5) { // ì™¼ìª½ ì–´ê¹¨
              leftShoulderDetected = true;
            }
            if (i === 6) { // ì˜¤ë¥¸ìª½ ì–´ê¹¨
              rightShoulderDetected = true;
            }
          } else {
            keypoints.push(null);
          }
        }

        // í‚¤í¬ì¸íŠ¸ ë°ì´í„°ë¥¼ ìƒìœ„ ì»´í¬ë„ŒíŠ¸ë¡œ ì „ë‹¬
        if (onKeypointsChange) {
          if (hasValidDetection) {
            // ëª© ê°ë„ ê³„ì‚°ì„ ìœ„í•œ í‚¤í¬ì¸íŠ¸ ì •ë³´ ë¡œê·¸
            const nose = keypoints[0];
            const leftShoulder = keypoints[5];
            const rightShoulder = keypoints[6];
            
            console.log('ğŸ“Š í‚¤í¬ì¸íŠ¸ ì „ë‹¬ (ìœ íš¨) - ì‹œê°„:', new Date().toLocaleTimeString(), {
              í‚¤í¬ì¸íŠ¸ìˆ˜: keypoints.length,
              ì–¼êµ´ê°ì§€: faceDetected,
              ì™¼ìª½ì–´ê¹¨: leftShoulderDetected,
              ì˜¤ë¥¸ìª½ì–´ê¹¨: rightShoulderDetected,
              ìœ íš¨ê°ì§€: hasValidDetection,
              ì½”ìœ„ì¹˜: nose ? `(${Math.round(nose.x)}, ${Math.round(nose.y)})` : 'ì—†ìŒ',
              ì™¼ìª½ì–´ê¹¨ìœ„ì¹˜: leftShoulder ? `(${Math.round(leftShoulder.x)}, ${Math.round(leftShoulder.y)})` : 'ì—†ìŒ',
              ì˜¤ë¥¸ìª½ì–´ê¹¨ìœ„ì¹˜: rightShoulder ? `(${Math.round(rightShoulder.x)}, ${Math.round(rightShoulder.y)})` : 'ì—†ìŒ'
            });
            onKeypointsChange(keypoints);
          } else {
            // ìœ íš¨í•˜ì§€ ì•Šì„ ë•Œ null ì „ë‹¬
            console.log('ğŸ“Š í‚¤í¬ì¸íŠ¸ ì „ë‹¬ (ë¬´íš¨) - ì‹œê°„:', new Date().toLocaleTimeString(), ': ê°ì§€ë˜ì§€ ì•ŠìŒ');
            onKeypointsChange(null);
          }
        }

        // í‚¤í¬ì¸íŠ¸ ì—°ê²°ì„  ê·¸ë¦¬ê¸° - íˆ¬ëª…í•˜ê²Œ ì„¤ì •
        ctx.strokeStyle = 'rgba(0, 255, 255, 0)'; // íˆ¬ëª…í•œ ì‹œì•ˆìƒ‰
        ctx.lineWidth = 2;
        KEYPOINT_CONNECTIONS.forEach(([p1Index, p2Index]) => {
          const p1 = keypoints[p1Index];
          const p2 = keypoints[p2Index];

          if (p1 && p2 && p1.score > KEYPOINT_VIS_THRESHOLD && p2.score > KEYPOINT_VIS_THRESHOLD) {
            ctx.beginPath();
            ctx.moveTo(p1.x, p1.y);
            ctx.lineTo(p2.x, p2.y);
            ctx.stroke();
          }
        });
        ctx.strokeStyle = 'rgba(0, 255, 0, 0)'; // íˆ¬ëª…í•œ ë¼ì„ìƒ‰
      }

      // ì–¼êµ´ê³¼ ì–‘ìª½ ì–´ê¹¨ê°€ ëª¨ë‘ ì¸ì‹ë˜ì—ˆì„ ë•Œë§Œ ìœ íš¨í•œ ê°ì§€ë¡œ íŒë‹¨
      hasValidDetection = hasValidDetection && faceDetected && leftShoulderDetected && rightShoulderDetected;

      // ì¸ì‹ ìƒíƒœ ë³€ê²½ ì½œë°± í˜¸ì¶œ
      if (onRecognitionChange) {
        onRecognitionChange(hasValidDetection);
      }

    } catch (error) {
      console.error("ì¶”ë¡  ë° ì‹œê°í™” ì˜¤ë¥˜:", error);
      setErrorMessage("ì¶”ë¡  ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì½˜ì†”ì„ í™•ì¸í•´ì£¼ì„¸ìš”.");
    } finally {
      // í…ì„œ ë©”ëª¨ë¦¬ í•´ì œ
      input.dispose();
      if (output) output.dispose();
      if (processedOutput && processedOutput !== output) processedOutput.dispose();
    }
  }, [model, videoRef, onRecognitionChange, onKeypointsChange]);

  // ì¶”ë¡  ì‹œì‘ ë° ì¤‘ì§€ ê´€ë¦¬
  useEffect(() => {
    console.log("=== ì¶”ë¡  ì‹œì‘ useEffect ì‹¤í–‰ ===");
    console.log("ëª¨ë¸ ìƒíƒœ:", !!model);
    console.log("ë¹„ë””ì˜¤ ref ìƒíƒœ:", !!videoRef.current);
    console.log("ìº”ë²„ìŠ¤ ref ìƒíƒœ:", !!canvasRef.current);
    
    if (!model) {
      console.log("âŒ ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•ŠìŒ");
      return;
    }
    
    if (!videoRef.current) {
      console.log("âŒ ë¹„ë””ì˜¤ refê°€ ì—†ìŒ");
      return;
    }
    
    if (!canvasRef.current) {
      console.log("âŒ ìº”ë²„ìŠ¤ refê°€ ì—†ìŒ");
      return;
    }

    console.log("âœ… ëª¨ë“  ìš”ì†Œ ì¤€ë¹„ë¨, ì¶”ë¡  ì‹œì‘...");

    const startPoseEstimation = () => {
      console.log("ğŸš€ í¬ì¦ˆ ì¶”ë¡  ì‹œì‘ í•¨ìˆ˜ í˜¸ì¶œ");
      
      if (intervalRef.current) {
        console.log("ê¸°ì¡´ ì¸í„°ë²Œ ì •ë¦¬");
        clearInterval(intervalRef.current);
      }
      
      intervalRef.current = setInterval(runPose, 1000);
      console.log("âœ… í¬ì¦ˆ ì¶”ë¡  ì¸í„°ë²Œ ì‹œì‘ (1ì´ˆ ê°„ê²©)");
    };

    const stopPoseEstimation = () => {
      console.log("ğŸ›‘ í¬ì¦ˆ ì¶”ë¡  ì¤‘ì§€ í•¨ìˆ˜ í˜¸ì¶œ");
      
      if (intervalRef.current) {
        clearInterval(intervalRef.current);
        intervalRef.current = null;
        console.log("âœ… í¬ì¦ˆ ì¶”ë¡  ì¸í„°ë²Œ ì¤‘ì§€ ì™„ë£Œ");
      } else {
        console.log("ì¸í„°ë²Œì´ ì´ë¯¸ ì¤‘ì§€ëœ ìƒíƒœ");
      }
    };

    // ë¹„ë””ì˜¤ê°€ ì´ë¯¸ ì¤€ë¹„ëœ ê²½ìš°
    if (videoRef.current.readyState === 4) {
      console.log("âœ… ë¹„ë””ì˜¤ê°€ ì´ë¯¸ ì¤€ë¹„ë¨ (readyState: 4)");
      startPoseEstimation();
    } else {
      console.log("â³ ë¹„ë””ì˜¤ ì¤€ë¹„ ëŒ€ê¸° ì¤‘... (readyState:", videoRef.current.readyState, ")");
      
      // ë¹„ë””ì˜¤ê°€ ì¤€ë¹„ë  ë•Œê¹Œì§€ ëŒ€ê¸°
      const handleLoadedData = () => {
        console.log("ğŸ¥ ë¹„ë””ì˜¤ ë¡œë“œ ì™„ë£Œ, ì¶”ë¡  ì‹œì‘");
        startPoseEstimation();
      };

      videoRef.current.addEventListener('loadeddata', handleLoadedData, { once: true });
      console.log("ë¹„ë””ì˜¤ loadeddata ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ ë“±ë¡");
      
      return () => {
        console.log("ğŸ§¹ ì¶”ë¡  useEffect ì •ë¦¬ í•¨ìˆ˜ ì‹¤í–‰");
        if (videoRef.current) {
          videoRef.current.removeEventListener('loadeddata', handleLoadedData);
          console.log("ë¹„ë””ì˜¤ ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ ì œê±°");
        }
        stopPoseEstimation();
      };
    }

    return stopPoseEstimation;
  }, [model, videoRef.current, canvasRef.current, runPose]);

  if (loading) {
    return (
      <div className="pose-loading">
        <div>ëª¨ë¸ ë¡œë”© ì¤‘...</div>
        <div style={{ fontSize: '12px', color: '#666', marginTop: '5px' }}>
          í™˜ê²½: {import.meta.env.DEV ? 'ê°œë°œ' : 'í”„ë¡œë•ì…˜'}
        </div>
      </div>
    );
  }

  if (errorMessage) {
    return <div className="pose-error">ì˜¤ë¥˜: {errorMessage}</div>;
  }

  return (
    <canvas
      ref={canvasRef}
      width={640}
      height={640}
      className="pose-canvas"
      style={{
        position: 'absolute',
        top: 0,
        left: 0,
        pointerEvents: 'none',
        zIndex: 10,
        width: '100%',
        height: '100%'
      }}
    />
  );
}

export default PoseDetectionComponent; 